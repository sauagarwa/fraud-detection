{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551bb6a1-763f-48a5-812d-4b2f02c15dcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deploy Specific Model Version to Red Hat OpenShift Data Science\n",
    "\n",
    "This notebook deploys the model.joblib file to OpenShift Data Science through Inference Service.\n",
    "It is required that the model.joblib and inference-service.yaml file exists.\n",
    "In the pipeline, the model.joblib file is generated by the preceding job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b818167b-eddf-4b4f-bc73-cf0d42db8eba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, time, subprocess\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0a6c95-c83c-4080-ae6f-e8b07e556721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking template:deployment/inference-service.yaml\n",
      "system:serviceaccount:worldline:fraud-detection-wb\n",
      "<_io.BufferedReader name=63>\n",
      "Deployed template deployment/inference-service.yaml. Version: 24-09-23-200017\n"
     ]
    }
   ],
   "source": [
    "storage_key=\"aws-connection-fraud-detection\"\n",
    "model_version=os.environ.get(\"model_version\", \"24-09-23-200017\").replace(\"model-\",\"\")\n",
    "model_name = 'fraud'\n",
    "\n",
    "template_data = {\"model_version\": model_version, \"storage_key\": storage_key, \"model_name\": model_name}\n",
    "\n",
    "def deploy_template(filename, template_data):\n",
    "    print(\"invoking template:\" + filename)\n",
    "    template = Template(open(filename).read())\n",
    "    rendered_template = template.render(template_data)\n",
    "\n",
    "    subprocess.run(['oc', 'whoami'])\n",
    "    ps = subprocess.Popen(['echo', rendered_template], stdout=subprocess.PIPE)\n",
    "    print(ps.stdout)\n",
    "    output = subprocess.check_output(['oc', 'apply', '-f', '-'], stdin=ps.stdout)\n",
    "    ps.wait()\n",
    "    print(f\"Deployed template {filename}. Version: {model_version}\")\n",
    "\n",
    "templates = ['deployment/inference-service.yaml']\n",
    "for t in templates:\n",
    "    deploy_template(t, template_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de5408-38a0-43b5-900b-e1e8e836d1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
